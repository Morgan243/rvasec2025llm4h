[project]
name = "rvasec2025l4h"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "arrow>=1.3.0",
    "bash-kernel>=0.10.0",
    "datasets>=3.6.0",
    "docx2txt==0.8",
    "fastapi>=0.115.12",
    "ffmpeg-python==0.2.0",
    "guidance>=0.2.1",
    "huggingface-hub==0.25.1",
    "instructor>=1.5.2",
    "jupyter>=1.1.1",
    "jupyter-cache>=1.0.1",
    "jupyter-console>=6.6.3",
    "jupyter-lsp>=2.2.5",
    "llama-cpp-python",
    "llama-index-core==0.12.0",
    "llama-index-embeddings-huggingface==0.4.0",
    "llama-index-readers-file==0.4.0",
    "local-deep-research",
    "markdown==3.7",
    "mistune==3.0.2",
    "mlflow>=2.21.3",
    "mmz",
    "numpy==1.26.4",
    "ollama>=0.4.8",
    "openai>=1.76.2",
    "paddleocr==2.9.1",
    "paddlepaddle==2.6.2",
    "pandas>=2.2.3",
    "pyaudio>=0.2.14",
    "pyinstaller==6.10.0",
    "pynput==1.7.7",
    "pyqt5==5.15.11",
    "quarto>=0.1.0",
    "simple-parsing>=0.1.7",
    "speechrecognition==3.10.4",
    "torchvision>=0.21.0",
    "transformers[torch]>=4.48.3",
    "whispercpp",
    "wikipedia>=1.4.0",
]

[tool.uv.sources]
whispercpp = { git = "https://github.com/stlukey/whispercpp.py" }
mmz = { path = "../MMZ", editable = true }
llama-cpp-python = { git = "https://github.com/abetlen/llama-cpp-python" }
local-deep-research = { path = "../EXTERNAL/local-deep-research" }
